{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(path)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = {'Text': [\"Hello, 123 @!£$%' \\''s    \\n hi\", \"456 World!\", \"789 IFOAloveU\",\" ciao http://www.google.com\"]}\n",
    "#df = pd.DataFrame(data)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci i pattern della REGEX\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "patterns = {\n",
    "            # r'\\d+': '',             # remove digits (numeri)\n",
    "            # r'n': '',               # rimuove tutte le n'\n",
    "            # r'[^\\w\\s]': '',         # remove punteggiatura e simboli ...,'@!£$%\n",
    "            # r'\\b\\w{1,2}\\b':'',      # remove all token less than2 characters\n",
    "            # r'(http|www)[^\\s]+':'', # remove website\n",
    "            # r'\\s+': ' '             # sostituisce tutti i multipli spazi con uno spazio\n",
    "            }\n",
    "\n",
    "def clean_column(df, column, patterns):\n",
    "    for pattern, replacement in patterns.items():\n",
    "        df[column] = df[column].str.replace(pattern, replacement)\n",
    "        df[column] = df[column].str.lower() # applica il lower\n",
    "    return df\n",
    "\n",
    "#solo in preview\n",
    "clean_column(df, 'Text', patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applichiamo la modifica o regex\n",
    "df = clean_column(df, 'Text', patterns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0] #vedi tutto il testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(map(str, df['text'])) #trasformi la collonna in stringa \n",
    "text = ''.join(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si potrebbe fare una wordcloud positiva e una negativa perchè ho 2 classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = list(map(str, df['text'])) #trasformi la collonna in stringa classe 0,1(da sostituire nel text )\n",
    "#text = ''.join(text)\n",
    "#es :\n",
    "#text = list(map(str, df['0'])) #trasformi la collonna in stringa \n",
    "#text = ''.join(text)\n",
    "\n",
    "#oppure \n",
    "\n",
    "#text = list(map(str, df['1'])) #trasformi la collonna in stringa \n",
    "#text = ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2 : EDA con WORDCLOUD\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(background_color = 'black', width = 800, height = 400,\n",
    "                      max_words = 180, contour_width = 3,\n",
    "                      max_font_size = 80, contour_color = 'steelblue',\n",
    "                      stopwords = STOPWORDS, random_state = 667)\n",
    "\n",
    "wordcloud.generate(text)\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 3: Definizre X e y (features testuali e Target)\n",
    "\n",
    "X = df['text']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 4: Vettorizzazione\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X).toarray()\n",
    "X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 5: TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X_tfidf = tfidfconverter.fit_transform(X_vect).toarray()\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 6: Split Training and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=667\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 7: Modellazione\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=667,max_depth=5)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "# accuracy score on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(y_pred, y_test)\n",
    "test_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "# accuracy score on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(y_pred, y_test)\n",
    "test_data_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Class0', 'Class1']\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Class0', 'Class1']\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(cm,cmap= \"Blues\", \n",
    "            linecolor = 'black', \n",
    "            linewidth = 1, \n",
    "            annot = True, \n",
    "            fmt='', \n",
    "            xticklabels = labels, \n",
    "            yticklabels = labels)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the test data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, random_state=667, max_iter=5, tol=None)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(y_test,y_pred)\n",
    "test_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Pipeline Finale (nuovo train test split su dati raw tetuali) à vuole i dati grezzi \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=667\n",
    "                                                    )\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "bow = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "tfidf = TfidfTransformer()\n",
    "clf =SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=667, max_iter=5, tol=None)\n",
    "#clf = classifier = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([\n",
    "                ('bow',bow),\n",
    "                ('tfidf',tfidf),\n",
    "                ('clf',clf),\n",
    "                ])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "test_data_accuracy = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#labels = ['class1', 'class2']\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(cm,cmap= \"Blues\", \n",
    "            linecolor = 'black', \n",
    "            linewidth = 1, \n",
    "            annot = True, \n",
    "            fmt='', \n",
    "            xticklabels = labels, \n",
    "            yticklabels = labels)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipe, X, y, scoring = 'f1_micro', cv = 8)\n",
    "\n",
    "print(f'scores={scores}')\n",
    "print(f'mean={np.mean(scores)}')\n",
    "print(f'std={np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipe,'NLPEs1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "uploaded_model = joblib.load('NLPEs1.pkl')\n",
    "pred = uploaded_model.predict(['very beautiful']) # 1 --> Diabetic\n",
    "pred[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
