{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(path)\n",
    "#df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per sostituire i Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.fillna(0) \n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = {'Text': [\"Hello, 123 @!£$%' \\''s    \\n hi\", \"456 World!\", \"789 IFOAloveU\",\" ciao http://www.google.com\"]}\n",
    "#df = pd.DataFrame(data)\n",
    "#df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vedere le prime 10 righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci i pattern della REGEX\n",
    "\n",
    "\n",
    "patterns = {\n",
    "            # r'\\d+': '',             # remove digits (numeri)\n",
    "            \n",
    "            # r'[^\\w\\s]': '',         # remove punteggiatura e simboli ...,'@!£$%\n",
    "            # r'\\b\\w{1,2}\\b':'',      # remove all token less than2 characters\n",
    "            # r'(http|www)[^\\s]+':'', # remove website\n",
    "            # r'\\s+': ' '             # sostituisce tutti i multipli spazi con uno spazio\n",
    "            }\n",
    "\n",
    "def clean_column(df, column, patterns):\n",
    "    for pattern, replacement in patterns.items():\n",
    "        df[column] = df[column].str.replace(pattern, replacement)\n",
    "        df[column] = df[column].str.lower() # applica il lower\n",
    "    return df\n",
    "\n",
    "#solo in preview\n",
    "clean_column(df, 'Text', patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applichiamo la modifica o regex\n",
    "df = clean_column(df, 'Text', patterns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0] #vedi la prima riga\n",
    "#df['text'].head(10) prime 10 righe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostra le classi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts() #tra [] si mette la colonna di cui si vuole sapere le classi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info per vedere se sono convertite in object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasformi in stringa se hai solo 1 classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(map(str, df['text'])) #trasformi la collonna in stringa \n",
    "text = ''.join(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rinonimare le colonne e splittarle in 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={0:'NOT DISASTER', 1: 'DISASTER'}\n",
    "#ovviamente queste sono 2 classi \n",
    "df['labels']=df['target'].map(mapping) #target è la colonna che voglio modificare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si potrebbe fare una wordcloud positiva e una negativa perchè ho 2 classi\n",
    "(questo NON ha le colonne divise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_neutral = list(map(str, df[df['sentiment']=='neutral']['text']))\n",
    "text_positive = list(map(str, df[df['sentiment']=='positive']['text']))\n",
    "text_negative = list(map(str, df[df['sentiment']=='negative']['text']))\n",
    "\n",
    "text_neutral = ''.join(text_neutral)\n",
    "text_positive = ''.join(text_positive)\n",
    "text_negative = ''.join(text_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2 : EDA con WORDCLOUD\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(background_color = 'black', width = 800, height = 400,\n",
    "                      max_words = 180, contour_width = 3,\n",
    "                      max_font_size = 80, contour_color = 'steelblue',\n",
    "                      stopwords = STOPWORDS, random_state = 667)\n",
    "\n",
    "wordcloud.generate(text)\n",
    "#wordcloud.generate(text_neutral) o altri paramentri\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per farti veder solo le colonne selezionate, elimini le altre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[['text', 'sentiment']]\n",
    "#df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino i valori nulli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 3: Definizre X e y (features testuali e Target)\n",
    "\n",
    "X = df['text']\n",
    "y = df['class']\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 4: Vettorizzazione\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X).toarray()\n",
    "X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_vect.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF = Termini di frequenza, IF = logaritmo. Quindi conteggia il peso delle parole attribuendo più valore alle parole meno frequenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 5: TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X_tfidf = tfidfconverter.fit_transform(X_vect).toarray()\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 6: Split Training and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=667\n",
    "                                                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelli di classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 7: Modellazione\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=667,max_depth=5)\n",
    "classifier.fit(X_train, y_train) \n",
    "# provo Random Forest\n",
    "# accuracy score on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(y_pred, y_test)\n",
    "test_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "classifier.fit(X_train, y_train) \n",
    "#provo il Multinomiale\n",
    "# accuracy score on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(y_pred, y_test)\n",
    "test_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the test data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, random_state=667, max_iter=5, tol=None)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(y_test,y_pred)\n",
    "test_data_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report (fare sotto il modello migliore)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lezione 10 conf.matrix.pdf per capire valori precision, recall, f1 score .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = ['Class0', 'Class1'] #questi valori sono da cambiare con i nomi delle classi\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# questa è quella generica e inserisce lui le classi "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = ['Class0', 'Class1'] questi valori sono da cambiare con i nomi delle classi\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(cm,cmap= \"Blues\", \n",
    "            linecolor = 'black', \n",
    "            linewidth = 1, \n",
    "            annot = True, \n",
    "            fmt='', \n",
    "            xticklabels = classifier.classes_, \n",
    "            yticklabels = classifier.classes_)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Pipeline Finale (nuovo train test split su dati raw tetuali) à vuole i dati grezzi \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=667\n",
    "                                                    )\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "bow = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "tfidf = TfidfTransformer() #inserire modello migliore scelto\n",
    "#clf =SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=667, max_iter=5, tol=None)\n",
    "#clf = classifier = MultinomialNB(alpha=0.1) #inserire modello migliore scelto dopo clf\n",
    "#clf = classifier = RandomForestClassifier(n_estimators=1000, random_state=667,max_depth=5)\n",
    "pipe = Pipeline([\n",
    "                ('bow',bow),\n",
    "                ('tfidf',tfidf),\n",
    "                ('clf',clf),\n",
    "                ])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "test_data_accuracy = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report sul modello scelto nella pipiline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#labels = ['class1', 'class2']\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# plt.figure(figsize = (10,8))\n",
    "# sns.heatmap(cm,cmap= \"Blues\", \n",
    "#             linecolor = 'black', \n",
    "#             linewidth = 1, \n",
    "#             annot = True, \n",
    "#             fmt='', \n",
    "#             xticklabels = classifier.classes_, \n",
    "#             yticklabels = classifier.classes_)\n",
    "\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"Actual\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation (il test è splittato su più parti del testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipe, X, y, scoring = 'f1_micro', cv = 8)\n",
    "\n",
    "print(f'scores={scores}')\n",
    "print(f'mean={np.mean(scores)}')\n",
    "print(f'std={np.std(scores)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipe,'NLPEs1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "uploaded_model = joblib.load('NLPEs1.pkl')\n",
    "pred = uploaded_model.predict(['very beautiful']) # 1 --> Diabetic sono esempi\n",
    "pred[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
